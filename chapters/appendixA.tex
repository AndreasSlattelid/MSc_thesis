\chapter{Estimating parameters for interest rate models} 

Our methodology will be based on \cite{remillard2013statistical}

\section{Vasicek}
We recall the Vasicek model: 
\begin{align*}
dr(t) &= \alpha[m - r(t)]dt + \sigma dW^{Q}(t)    
\end{align*}

With explicit solution:
\begin{align}
\label{eq: r_VAS_explicit}
r(T) &= e^{-\alpha(T)}r(0) + m[1-e^{-\alpha(T)}] 
+ \sigma \int_{0}^{T}e^{-\alpha(T-u)}dW^{Q}(u) \nonumber \\ 
&= 
m + e^{-\alpha T}\left[r(0) -m \right]
+ \sigma \int_{0}^{T}e^{-\alpha(T-u)}dW^{Q}(u)
\end{align} 

\begin{definition}[\textbf{AR(p)-process}]
A stochastic process $X = (X_{t})_{t \in \mathcal{I}}$, where $\mathcal{I}$ is an index set, is said to be an $AR(p)$-process if it can be written as:
\begin{align*}
X_{t} &= \sum_{i=1}^{p}\eta_{i}X_{t-i} + \epsilon_{t} 
\end{align*}
Where $\epsilon_{t}$ is referred to as white noise, meaning that: 
\begin{align*}
\epsilon_{t} \sim \mathcal{N}\left(
0, \sigma_{w}^{2}
\right)    
\end{align*}
here $\sigma_{w}^{2}$ corresponds to a constant variance. 
\end{definition} 

\begin{proposition}[\textbf{\cite{remillard2013statistical}}]
One can express the Vasicek model as an $AR(1)$-process: 
\begin{align*}
r_{k}-m &= \eta (r_{k-1}-m) + \epsilon_{k}, \; k = 1, \dots, n     
\end{align*}
Where:
\begin{itemize}[leftmargin =*]
    \item $r_{k} := r(kh)$, here $r$ is as described in Equation \ref{eq: r_VAS_explicit}.
    \item $\eta = e^{-\alpha h}$
    \item $\epsilon_{k} \sim \mathcal{N}\left(
    0, \sigma^{2}\left[
    \frac{1-\eta^{2}}{2\alpha}
    \right]\right)$, here we can interpret: 
    $\sigma_{w}^{2} = \sigma^{2}\left[
    \frac{1-\eta^{2}}{2\alpha}
    \right]$
\end{itemize}
\end{proposition}

\newpage 
\textbf{Maximum Likelihood Estimation}
\\~\\ 
We can find the MLE \nomenclature{MLE}{Maximum Likelihood Estimation}  estimates for $\bm{\theta} = (\alpha, m, \sigma)$. We note that our $AR(1)$-series $r = (r_{k})_{\{k = 1, \dots, n\}}$ is markovian, meaning that: 
\begin{align*}
r_{k}|r_{k-1}, \dots, r_{0} \stackrel{d}{=} r_{k}|r_{k-1}    
\end{align*}

This means that: 
\begin{align*}
L(\bm{\theta}) &= f_{\bm{\theta}}(r_{1}, \dots, r_{n}|r_{0}) \\ 
&= \prod_{k=1}^{n}f_{\bm{\theta}}(r_{k}|r_{k-1})
\end{align*}

We have that 
\[
r_{k}|r_{k-1} \sim \mathcal{N}\left(
\E[r_{k}|r_{k-1}], Var[r_{k}|r_{k-1}]
\right)
\]

as: 
\begin{align*}
r_{k} &= \underbrace{m + e^{-\alpha h}(r_{k-1}-m)}_{= \E[r_{k}|r_{k-1}]} 
+ \underbrace{\epsilon_{k}}_{\sim \mathcal{N}(0, \sigma_{w}^{2})}    
\end{align*}

Meaning that: 
\begin{align*}
r_{k}|r_{k-1} \sim \mathcal{N}\left(
\underbrace{
m + e^{-\alpha h}[r_{k-1}-m]
}_{= \mu}, 
\underbrace{
\frac{\sigma^{2}}{2\alpha}\left[1-e^{-2\alpha h}\right]
}_{= \gamma^{2}}
\right)    
\end{align*}

Now: 
\begin{align*}
f_{\mathcal{N}(\mu, \gamma^{2})}(r_{k}) &=
\frac{1}{\sqrt{2\pi}\gamma}\exp\left(
-\frac{1}{2\gamma^{2}}\left[r_{k} - \mu \right]^{2}
\right)
\end{align*}

This gives us: 
\begin{align*}
L(\bm{\theta}) &= \prod_{k=1}^{n}f_{\bm{\theta}}(r_{k}|r_{k-1}) \\ 
&= 
\prod_{k=1}^{n}f_{\mathcal{N}(\mu, \gamma^{2})}(r_{k}) 
\\ 
&= 
(2\pi\gamma^{2})^{-\frac{n}{2}}\exp\left(
-\frac{1}{2\gamma^{2}}\sum_{k=1}^{n}\left(
r_{k} - \mu
\right)^{2}
\right) \\ 
&\Downarrow \\ 
l(\bm{\theta}) &:= \ln L(\bm{\theta}) \\
&= 
-\frac{n}{2}\ln(2\pi) - \frac{n}{2}\ln(\gamma^{2})
-\frac{1}{2\gamma^{2}}\sum_{k=1}^{n}\left(r_{k} - \mu \right)^{2}
\end{align*}

\newpage
From \cite{Chalmers_MSc}, we can infer the following estimates: 
\begin{align*}
\hat{\alpha} &= 
-\frac{1}{n}\ln\left[
\frac{
n\sum_{k=1}^{n}r_{k}r_{k-1} - \sum_{k=1}^{n}r_{k}\sum_{k=1}^{n}r_{k-1}
}{
n\sum_{k=1}^{n}r_{k-1}^{2} - \left(\sum_{k=1}^{n}r_{k-1}\right)^{2}
}
\right] \\ 
\\ 
\hat{m} &= 
\frac{1}{n[1-e^{\hat{\alpha}h}]}
\left[
\sum_{k=1}^{n}r_{k} - e^{-\hat{\alpha}h}\sum_{k=1}^{n}r_{k-1}
\right] \\ 
\\ 
\hat{\sigma}^{2} &= 
\frac{
2\hat{\alpha}
}
{
n[1-e^{-2\hat{\alpha}h}]
}
\sum_{k=1}^{n}\left(
r_{k} - r_{k-1}e^{-\hat{\alpha}h} 
- \hat{m}[1-e^{-\hat{\alpha}h}]
\right)^{2}
\end{align*} 

\textbf{Kalman Filter}
\\~\\ 
hei
















\newpage 
Our approach will be based on \cite{halga2014}. We have the following relationship: 
\begin{align*}
P(t,T) &= e^{-R(t,T)(T-t)}
\end{align*}
Here $R(t,T)$ is the zero coupon yield also called the yield term structure. 


We will study interest rates which are ATS, meaning that the zero-coupon bond can be written as:
\begin{align*}
P(t,T) &= 
\exp\left(
-A(t,T) -B(t,T)r(t)
\right)
\end{align*}

This gives us the following relationship between ATS and zero-coupon yields: 
\begin{align*}
R(t,T) &= \frac{
A(t,T) + B(t,T)r(t)
}{
T-t
}    
\end{align*}

Assume that there are $n$ observations, and $M$ maturities, we denote: 
\begin{itemize}
    \item $\tau_{j} := T_{j} - t_{i}$
    \item $R_{ij}$: the observed zero-coupon yield on day $i$ with maturity $j$. 
\end{itemize}

\textbf{Vasicek}
\\~\\
Our goal will be to minimize the following: 
\begin{align*}
\argmin\limits_{(\alpha, m, \sigma, r_{i}) \in \R^{4}}
S_{i}(\alpha, m, \sigma, r_{i}, \tau_{j}) 
&= 
\sum_{j=1}^{M}\left[
R_{ij} - R^{VAS}(\alpha, m, \sigma, r_{i}, \tau_{j})
\right]^{2}
\end{align*}

Here: 
\begin{align*}
R^{VAS}(\alpha, m, \sigma, r_{i}, \tau_{j})
&= 
\frac{
A^{VAS}(\alpha, m, \sigma, \tau_{j}) + B^{VAS}(\alpha, \tau_{j})r_{i}
}{
\tau_{j}
} 
\end{align*}

Where: 
\begin{align*}
B^{VAS}(\alpha, \tau_{j}) &= \frac{1}{\alpha}\left[
1 - e^{-\alpha \tau_{j}}
\right] \\ 
A^{VAS}(\alpha, m, \sigma, \tau_{j})
&= 
\left(
\frac{\sigma^{2}}{2\alpha^{2}} - m
\right)\left[
\tau_{j} - B^{VAS}(\alpha, \tau_{j})
\right]
+ \frac{\sigma^{2}}{4\alpha}B^{2}(\alpha, \tau_{j})
\end{align*}

\newpage 

s



\newpage 
For simulation purposes, we have collected zero-coupon yields from the Bank of Canada \cite{Canada_termyields}. We have collected data from 22/Mar/2013-08/Mar/2023: 
\\~\\ 
\textbf{Plot here}
\\~\\



